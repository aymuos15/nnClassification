# Data Preparation Guide

## Overview

This framework uses **index-based cross-validation splits** to avoid data duplication while supporting k-fold cross-validation.

**Key benefits:**
- ✅ **No data duplication** - Single copy of images in `raw/` directory
- ✅ **Reproducible splits** - Deterministic fold generation via fixed seeds
- ✅ **Version control friendly** - Lightweight index files can be committed to git
- ✅ **Flexible** - Regenerate splits anytime with different parameters

---

## ⚠️ MANDATORY DIRECTORY STRUCTURE

**Your dataset MUST follow this structure:**

```
data/your_dataset/
├── raw/                    # Single source of truth - all your images here
│   ├── class1/            # One folder per class
│   │   ├── img1.jpg
│   │   ├── img2.jpg
│   │   └── ...
│   ├── class2/
│   │   ├── img3.jpg
│   │   └── ...
│   └── classN/
│
└── splits/                 # Generated by splitting.py (DO NOT create manually)
    ├── fold_0_train.txt   # Index file: contains paths like "raw/class1/img1.jpg"
    ├── fold_0_val.txt
    ├── fold_0_test.txt
    ├── fold_1_train.txt
    ├── fold_1_val.txt
    ├── fold_1_test.txt
    └── ...
```

**Critical subdirectories:**
- `raw/` - Contains your original images organized by class (you create this)
- `splits/` - Contains index files that reference images in `raw/` (generated by `splitting.py`)

---

## Requirements (ALL MANDATORY)

1. ✅ **raw/ directory:** All images organized by class in subdirectories
2. ✅ **Class folders:** Each class in its own subdirectory under `raw/`
3. ✅ **Images in class folders:** Images directly inside class folders (no nested subdirectories)
4. ✅ **splits/ directory:** Generated automatically by `splitting.py`
5. ✅ **Matching num_classes:** Number of class folders must equal `model.num_classes` in config

---

## Step-by-Step Setup

### Step 1: Organize Raw Data

Create the `raw/` directory with your images organized by class:

```bash
# Create directory structure
mkdir -p data/my_dataset/raw

# Move your images into class folders
mkdir -p data/my_dataset/raw/class1
mkdir -p data/my_dataset/raw/class2
mkdir -p data/my_dataset/raw/class3

# Move images to appropriate folders
mv /path/to/class1_images/* data/my_dataset/raw/class1/
mv /path/to/class2_images/* data/my_dataset/raw/class2/
mv /path/to/class3_images/* data/my_dataset/raw/class3/
```

**Verify structure:**
```bash
tree -L 2 data/my_dataset/

# Expected output:
# data/my_dataset/
# └── raw/
#     ├── class1/
#     ├── class2/
#     └── class3/
```

### Step 2: Generate Cross-Validation Splits

Use `splitting.py` to generate index files for k-fold cross-validation:

```bash
python splitting.py \
  --raw_data data/my_dataset/raw \
  --output data/my_dataset/splits \
  --folds 5 \
  --ratio 0.7 0.15 0.15 \
  --seed 42
```

**Parameters:**
- `--raw_data`: Path to your `raw/` directory
- `--output`: Where to save split index files (typically `data/my_dataset/splits`)
- `--folds`: Number of CV folds to generate (default: 5)
- `--ratio`: Train/val/test split ratios (default: 0.7 0.15 0.15)
- `--seed`: Random seed for reproducibility (default: 42)

**Output:**
```
data/my_dataset/
├── raw/
│   ├── class1/
│   ├── class2/
│   └── class3/
└── splits/
    ├── fold_0_train.txt
    ├── fold_0_val.txt
    ├── fold_0_test.txt
    ├── fold_1_train.txt
    ├── fold_1_val.txt
    ├── fold_1_test.txt
    ├── fold_2_train.txt
    ├── fold_2_val.txt
    ├── fold_2_test.txt
    ├── fold_3_train.txt
    ├── fold_3_val.txt
    ├── fold_3_test.txt
    ├── fold_4_train.txt
    ├── fold_4_val.txt
    └── fold_4_test.txt
```

**Index file format:**
Each index file contains one image path per line (relative to parent of `raw/`):
```
raw/class1/img001.jpg
raw/class1/img002.jpg
raw/class2/img003.jpg
...
```

### Step 3: Update Configuration

Edit `ml_src/config.yaml`:

```yaml
data:
  dataset_name: 'my_dataset'  # Used for run directory naming
  data_dir: 'data/my_dataset' # Must contain raw/ and splits/
  fold: 0                      # Which fold to use (0-indexed)

model:
  num_classes: 3  # Must match number of class folders in raw/
```

### Step 4: Train

```bash
# Train fold 0
python train.py --fold 0

# Train other folds
python train.py --fold 1
python train.py --fold 2
```

---

## ✅ Complete Example: Ants vs Bees Dataset

### Directory Structure
```
data/hymenoptera_data/
├── raw/
│   ├── ants/
│   │   ├── 0013035.jpg
│   │   ├── 1030023.jpg
│   │   └── ... (244 images total)
│   └── bees/
│       ├── 1092977343_cb42b38d62.jpg
│       ├── 1093831624_fb5fbe2308.jpg
│       └── ... (250 images total)
└── splits/
    ├── fold_0_train.txt (70% of images)
    ├── fold_0_val.txt (15% of images)
    ├── fold_0_test.txt (15% of images)
    ├── fold_1_train.txt
    └── ...
```

### Configuration
```yaml
data:
  dataset_name: 'hymenoptera'
  data_dir: 'data/hymenoptera_data'
  fold: 0

model:
  num_classes: 2  # ants, bees = 2 classes
```

### Training Commands
```bash
# Generate splits (one time only)
python splitting.py \
  --raw_data data/hymenoptera_data/raw \
  --output data/hymenoptera_data/splits \
  --folds 5

# Train different folds
python train.py --fold 0  # Creates runs/hymenoptera_base_fold_0/
python train.py --fold 1  # Creates runs/hymenoptera_base_fold_1/
python train.py --fold 2  # Creates runs/hymenoptera_base_fold_2/
```

---

## Verification

### Verify Dataset Structure

```bash
#!/bin/bash
# verify_structure.sh

echo "Checking data/my_dataset..."

# Check raw/ directory
if [ ! -d "data/my_dataset/raw" ]; then
  echo "❌ ERROR: raw/ directory not found"
  exit 1
fi

# Check for classes
classes=$(ls -d data/my_dataset/raw/*/ 2>/dev/null | wc -l)
if [ $classes -eq 0 ]; then
  echo "❌ ERROR: No class folders in raw/"
  exit 1
fi
echo "✓ Found $classes classes in raw/"

# Check splits/ directory
if [ ! -d "data/my_dataset/splits" ]; then
  echo "❌ ERROR: splits/ directory not found"
  echo "   Run: python splitting.py --raw_data data/my_dataset/raw --output data/my_dataset/splits"
  exit 1
fi

# Check for index files
folds=$(ls data/my_dataset/splits/fold_*_train.txt 2>/dev/null | wc -l)
if [ $folds -eq 0 ]; then
  echo "❌ ERROR: No split files found in splits/"
  echo "   Run: python splitting.py --raw_data data/my_dataset/raw --output data/my_dataset/splits"
  exit 1
fi
echo "✓ Found $folds folds in splits/"

# Count images per class
echo ""
echo "Images per class:"
for class_dir in data/my_dataset/raw/*/; do
  class_name=$(basename "$class_dir")
  count=$(find "$class_dir" -type f | wc -l)
  echo "  $class_name: $count images"
done

echo ""
echo "✅ Dataset structure is valid!"
```

### Count Images Per Split

```bash
# Check fold 0 split sizes
echo "Fold 0 split sizes:"
echo "  Train: $(wc -l < data/my_dataset/splits/fold_0_train.txt) images"
echo "  Val:   $(wc -l < data/my_dataset/splits/fold_0_val.txt) images"
echo "  Test:  $(wc -l < data/my_dataset/splits/fold_0_test.txt) images"
```

---

## Supported Image Formats

The framework supports any format that PIL/Pillow can read:
- **Common formats:** JPG, JPEG, PNG, BMP, GIF, TIFF
- **Others:** WebP, PPM, PGM, PBM, etc.

**Recommendation:** Use JPG or PNG for best compatibility.

---

## Dataset Split Ratios

### Recommended Splits

| Total Images | Train | Val | Test |
|--------------|-------|-----|------|
| < 1,000 | 70% | 15% | 15% |
| 1,000 - 10,000 | 70% | 20% | 10% |
| 10,000+ | 80% | 10% | 10% |

### Why Three Splits?

- **Train:** Used for training the model (gradient updates)
- **Val:** Used for hyperparameter tuning and model selection
- **Test:** Final evaluation (never seen during training or validation)

**Important:** Never use test set during training or validation!

---

## Troubleshooting

### Problem: "Index file not found"

**Error:**
```
FileNotFoundError: Index file not found: data/my_dataset/splits/fold_0_train.txt
```

**Cause:** Haven't generated splits yet.

**Solution:**
```bash
python splitting.py \
  --raw_data data/my_dataset/raw \
  --output data/my_dataset/splits \
  --folds 5
```

---

### Problem: "No such file or directory" when loading images

**Error:**
```
RuntimeError: Error loading image data/my_dataset/raw/class1/img1.jpg
```

**Cause:** Index file references image that doesn't exist.

**Solutions:**
1. Check if images are in `raw/` directory
2. Regenerate splits if you moved/deleted images:
   ```bash
   python splitting.py --raw_data data/my_dataset/raw --output data/my_dataset/splits --folds 5
   ```

---

### Problem: "Doesn't match num_classes"

**Error:**
```
RuntimeError: Model output size (2) doesn't match dataset classes (3)
```

**Solution:** Update `num_classes` in config:
```yaml
model:
  num_classes: 3  # Match number of class folders in raw/
```

---

### Problem: Empty class folders

**Error:**
```
ValueError: Found 0 files in raw/class1/
```

**Cause:** Class folder exists but has no images.

**Solution:** Add images to the folder or remove the empty folder.

---

## Advanced: Custom Organization Script

If you need to programmatically organize your data:

```python
#!/usr/bin/env python3
"""
organize_raw_data.py - Organize images into raw/ directory
"""
import os
import shutil
from pathlib import Path

SOURCE_DIR = 'original_data/'  # Your current data location
TARGET_DIR = 'data/my_dataset/raw/'  # Where to organize
CLASSES = ['class1', 'class2', 'class3']

# Create target directories
for class_name in CLASSES:
    os.makedirs(os.path.join(TARGET_DIR, class_name), exist_ok=True)

# Copy images to raw/ directory
for class_name in CLASSES:
    source_class_dir = os.path.join(SOURCE_DIR, class_name)
    target_class_dir = os.path.join(TARGET_DIR, class_name)
    
    images = [f for f in os.listdir(source_class_dir) 
              if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
    
    print(f"Copying {len(images)} images for {class_name}...")
    for img in images:
        shutil.copy2(
            os.path.join(source_class_dir, img),
            os.path.join(target_class_dir, img)
        )

print("Done! Now generate splits:")
print("python splitting.py --raw_data data/my_dataset/raw --output data/my_dataset/splits")
```

---

## Best Practices

1. **Keep raw/ immutable** - Never modify files in `raw/` after creating splits
2. **Use consistent seeds** - Same seed = same splits (reproducibility)
3. **Commit splits to git** - Index files are small and ensure reproducibility
4. **Document your splits** - Note the exact `splitting.py` command used
5. **Backup raw data** - Keep a copy of original unorganized data
6. **Verify before training** - Use verification scripts above
7. **Regenerate if needed** - Safe to regenerate splits anytime (with same seed for consistency)

---

## Summary

✅ **Checklist:**
- [ ] Images organized in `raw/class_name/` directories
- [ ] Generated splits using `splitting.py`
- [ ] Verified `raw/` and `splits/` directories exist
- [ ] Updated `dataset_name` in config
- [ ] Updated `data_dir` in config
- [ ] Set `num_classes` correctly in config
- [ ] Ready to train with `--fold 0`, `--fold 1`, etc.

**Remember:** This structure is **mandatory**. The code will not work without it. Take time to organize your data properly—it will save hours of debugging later!

---

## Next Steps

After organizing your data:

1. **Update configuration:**
   ```yaml
   data:
     dataset_name: 'my_dataset'
     data_dir: 'data/my_dataset'
     fold: 0
   model:
     num_classes: <your_num_classes>
   ```

2. **Start training:**
   ```bash
   python train.py --fold 0
   ```

3. **See:** [Quick Start Guide](quick-start.md) and [Training Guide](../user-guides/training.md)
