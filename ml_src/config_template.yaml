# Base configuration for PyTorch classifier training

# Reproducibility configuration
seed: 42
deterministic: false  # Set to true for full determinism (slower but completely reproducible)

# Data configuration
data:
  # Dataset name (used in run directory naming)
  dataset_name: 'hymenoptera'

  # Base directory: must contain raw/ (images) and splits/ (index files from splitting.py)
  data_dir: 'data/hymenoptera_data'

  # Cross-validation settings
  fold: 0                     # Which fold to use (0-indexed)

  num_workers: 4

# Training configuration
training:
  # Trainer type: Selects the training strategy
  # Options: 'standard', 'mixed_precision', 'accelerate', 'dp'
  # - 'standard': Traditional PyTorch training (default, backward compatible)
  # - 'mixed_precision': Automatic Mixed Precision (AMP) training for faster training with reduced memory
  # - 'accelerate': HuggingFace Accelerate for multi-GPU/distributed training
  # - 'dp': Differential privacy training with Opacus (requires: pip install opacus)
  # Can be omitted - defaults to 'standard'
  trainer_type: 'standard'

  # Mixed precision settings (only used when trainer_type: 'mixed_precision')
  # amp_dtype: 'float16'  # Options: 'float16' (faster, default) or 'bfloat16' (more stable)
  # Note: Mixed precision requires CUDA. Falls back to standard training on CPU.

  # Accelerate settings (only used when trainer_type: 'accelerate')
  # gradient_accumulation_steps: 1  # Accumulate gradients over N batches (useful for large models)
  # Usage:
  #   Single device: python ml-train --config config.yaml
  #   Multi-GPU: accelerate launch ml-train --config config.yaml
  # Note: Multi-GPU requires one-time setup with `accelerate config`

  # Differential privacy settings (only used when trainer_type: 'dp')
  # Requires installation: pip install opacus OR pip install -e ".[dp]"
  # dp:
  #   noise_multiplier: 1.1  # Privacy noise level (higher = more privacy, lower utility)
  #   max_grad_norm: 1.0     # Gradient clipping threshold (lower = more privacy)
  #   target_epsilon: 3.0    # Privacy budget target (lower = stronger privacy, < 10 recommended)
  #   target_delta: 1e-5     # Privacy delta (typically 1/dataset_size)
  # Privacy-Utility Tradeoff:
  #   - Epsilon < 1: Very strong privacy (high utility loss)
  #   - Epsilon 1-10: Good privacy-utility balance
  #   - Epsilon > 10: Weaker privacy guarantees
  # Note: Training with DP is slower and may require more epochs for convergence

  batch_size: 4
  num_epochs: 3
  device: 'cuda:0'  # Will fallback to cpu if cuda not available

  # Early stopping configuration
  early_stopping:
    enabled: false         # Enable early stopping to prevent overfitting
    patience: 10           # Number of epochs to wait for improvement before stopping
    metric: 'val_acc'      # Metric to monitor: 'val_acc' or 'val_loss'
    mode: 'max'            # 'max' for accuracy (higher is better), 'min' for loss (lower is better)
    min_delta: 0.0         # Minimum change in metric to qualify as improvement

# Inference settings
inference:
  # Inference strategy: Selects the inference optimization strategy
  # Options: 'standard', 'mixed_precision', 'accelerate'
  # - 'standard': Traditional PyTorch inference (default, backward compatible, works on CPU/GPU)
  # - 'mixed_precision': Automatic Mixed Precision (AMP) inference for 2-3x speedup on GPU
  # - 'accelerate': HuggingFace Accelerate for multi-GPU/distributed inference
  # Can be omitted - defaults to 'standard'
  strategy: 'standard'

  # Mixed precision inference settings (only used when strategy: 'mixed_precision')
  # amp_dtype: 'float16'  # Options: 'float16' (faster, default) or 'bfloat16' (more stable)
  # Note: Mixed precision requires CUDA. Falls back to standard inference on CPU.

# Optimizer configuration
optimizer:
  lr: 0.001
  momentum: 0.9

# Learning rate scheduler configuration
scheduler:
  step_size: 7
  gamma: 0.1

# Model configuration
model:
  # Model type: 'base' for torchvision models, 'custom' for custom architectures
  type: 'base'

  # For base models: specify any torchvision architecture
  # Options: resnet18, resnet50, vgg16, efficientnet_b0, mobilenet_v2, etc.
  architecture: 'resnet18'

  # For custom models: specify custom architecture name
  # Options: 'simple_cnn', 'tiny_net'
  custom_architecture: null

  # Number of output classes
  num_classes: 2

  # Pretrained weights: 'DEFAULT' for ImageNet weights, null for random initialization
  weights: null

  # Additional parameters for custom models
  input_size: 224  # Input image size (for custom models)
  dropout: 0.5     # Dropout probability (for custom models that support it)

  # Legacy option (deprecated but kept for compatibility)
  model_path: 'best_model.pth'

# Data augmentation configuration
transforms:
  train:
    resize: [224, 224]
    random_horizontal_flip: true
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

  val:
    resize: [224, 224]
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

  test:
    resize: [224, 224]
    normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
