# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Production-ready PyTorch image classification framework with flexible architecture support, index-based cross-validation, and comprehensive experiment tracking. Built as an installable Python package with CLI tools.

## Core Development Commands

### Installation & Setup
```bash
# Install in editable mode with dev dependencies
pip install -e ".[dev]"
```

### Testing
```bash
# Run all tests
pytest

# Run tests with verbose output
pytest -v

# Run specific test file
pytest tests/test_architectures.py

# Run tests with coverage
pytest --cov=ml_src
```

### Code Quality
```bash
# Format and lint code using ruff
ruff format .
ruff check .

# Fix auto-fixable issues
ruff check --fix .
```

### Documentation
```bash
# Build documentation locally
mkdocs build

# Serve documentation with live reload
mkdocs serve

# Deploy to GitHub Pages
mkdocs gh-deploy
```

### CLI Tools (after installation)
```bash
# Generate dataset configuration
ml-init-config data/my_dataset

# Create cross-validation splits
ml-split --raw_data data/my_dataset/raw --folds 5

# Train model
ml-train --config configs/my_dataset_config.yaml

# Run inference
ml-inference --checkpoint_path runs/my_run/weights/best.pt

# Visualize with TensorBoard
ml-visualise --mode launch --run_dir runs/my_run
```

## Architecture

### Package Structure

```
ml_src/
├── cli/                    # CLI entry points (installed as console scripts)
│   ├── init_config.py      # ml-init-config: Generate dataset configs
│   ├── train.py            # ml-train: Main training orchestrator
│   ├── inference.py        # ml-inference: Test/inference runner
│   ├── splitting.py        # ml-split: CV split generator
│   └── visualise.py        # ml-visualise: TensorBoard utilities
│
└── core/                   # Reusable ML components (no CLI dependencies)
    ├── dataset.py          # IndexedImageDataset (index-based loading)
    ├── loader.py           # DataLoader creation
    ├── network/            # Model architectures
    │   ├── __init__.py     # get_model() API (routes base vs custom)
    │   ├── base.py         # Torchvision models (ResNet, EfficientNet, etc.)
    │   └── custom.py       # Custom architectures (SimpleCNN, TinyNet)
    ├── loss.py             # Loss functions
    ├── optimizer.py        # Optimizers and schedulers
    ├── trainer.py          # Training loop
    ├── test.py             # Evaluation/testing
    ├── metrics.py          # Classification reports, confusion matrices
    ├── checkpointing.py    # Checkpoint save/load, summaries
    └── seeding.py          # Reproducibility (seed setting)
```

### Key Design Principles

1. **CLI vs Core Separation**: `cli/` orchestrates workflows, `core/` contains reusable components. Never import CLI modules from core modules.

2. **Index-based Cross-Validation**: Dataset uses text files (e.g., `fold_0_train.txt`) containing relative paths to images in `data_dir/raw/`. This avoids duplicating data across folds.

3. **Configuration System**:
   - Base config template: `ml_src/config_template.yaml`
   - Dataset-specific configs: `configs/{dataset_name}_config.yaml` (auto-generated by `ml-init-config`)
   - CLI overrides: Use `--batch_size`, `--lr`, `--fold`, etc. to override config values

4. **Model Loading**: `get_model(config, device)` routes to either:
   - `base.py` for torchvision models (requires `model.type: 'base'`, `model.architecture: 'resnet18'`)
   - `custom.py` for custom models (requires `model.type: 'custom'`, `model.custom_architecture: 'simple_cnn'`)

5. **Run Directory Naming**: Auto-generated as `runs/{dataset_name}_{overrides}_fold_{N}/` where overrides include non-default parameters (e.g., `hymenoptera_batch_32_lr_0.01_fold_0`)

### Data Flow

1. **Dataset Creation** (`core/dataset.py`):
   - `get_datasets(config)` → reads index files from `data_dir/splits/`
   - Creates `IndexedImageDataset` for train/val/test splits
   - Test set is shared across all folds

2. **Training** (`cli/train.py` → `core/trainer.py`):
   - Loads config, overrides with CLI args
   - Creates run directory with auto-generated name
   - Sets up logging (console + file + TensorBoard)
   - Trains model, saves best/last checkpoints
   - Auto-runs test evaluation after training completes

3. **Checkpointing** (`core/checkpointing.py`):
   - `save_checkpoint()`: Saves full state (model, optimizer, scheduler, epoch, metrics history)
   - `load_checkpoint()`: Restores complete training state for resumption
   - Best model saved to `weights/best.pt`, last to `weights/last.pt`

## Critical Implementation Details

### Adding New Models

**Torchvision models** (e.g., ConvNeXt):
1. No code changes needed
2. Update config: `model.architecture: 'convnext_tiny'`

**Custom models**:
1. Add architecture to `ml_src/core/network/custom.py` in `MODEL_REGISTRY`
2. Ensure it accepts `num_classes`, `dropout` parameters
3. Update config: `model.type: 'custom'`, `model.custom_architecture: 'your_model'`

### Dataset Requirements

Mandatory directory structure:
```
data/{dataset_name}/
├── raw/                    # Original images (never modified)
│   ├── class1/
│   │   ├── img1.jpg
│   │   └── ...
│   └── class2/
└── splits/                 # Generated by ml-split
    ├── test.txt            # Shared test set (all folds)
    ├── fold_0_train.txt
    ├── fold_0_val.txt
    ├── fold_1_train.txt
    └── ...
```

Index files contain relative paths: `raw/class1/img1.jpg`

### Configuration Override Behavior

CLI arguments override config file:
```bash
# Config has batch_size: 4, lr: 0.001
ml-train --config config.yaml --batch_size 32 --lr 0.01
# Results in: batch_size=32, lr=0.01, run_name includes "batch_32_lr_0.01"
```

Override-based parameters are added to run directory name for easy tracking.

### Logging System

- **loguru** for structured logging with color-coded levels
- Console output: Color-coded, formatted timestamps
- File output: `runs/{run_name}/logs/train.log`
- TensorBoard: `runs/{run_name}/tensorboard/` (metrics, confusion matrices, classification reports)

### Reproducibility

Set in config:
```yaml
seed: 42
deterministic: false  # true for full reproducibility (slower)
```

`core/seeding.py` handles:
- Python random seed
- NumPy seed
- PyTorch seed (CPU + CUDA)
- Deterministic algorithms (if enabled)

## Testing Guidelines

- Test files in `tests/` follow `test_*.py` naming
- Use `pytest` fixtures from `tests/conftest.py`
- Current coverage: Model architecture loading (`test_architectures.py`)
- When adding models, add corresponding tests to verify they load correctly

## Common Workflows

### Training a New Dataset
1. Organize data in `data/{name}/raw/class1/`, `data/{name}/raw/class2/`, etc.
2. Run `ml-split --raw_data data/{name}/raw --folds 5`
3. Run `ml-init-config data/{name}` → creates `configs/{name}_config.yaml`
4. Edit config if needed (model architecture, hyperparameters)
5. Run `ml-train --config configs/{name}_config.yaml`

### Resuming Training
```bash
ml-train --config configs/my_config.yaml --resume runs/my_run/weights/last.pt
```
Restores: model weights, optimizer state, scheduler state, epoch counter, best accuracy, loss/accuracy history

### Cross-Validation
Train each fold separately:
```bash
ml-train --config configs/my_config.yaml --fold 0
ml-train --config configs/my_config.yaml --fold 1
ml-train --config configs/my_config.yaml --fold 2
```
Test set is identical across all folds; only train/val splits differ.

## Documentation Structure

Comprehensive docs in `docs/`:
- **getting-started/**: Installation, data prep, quick start
- **configuration/**: All config parameters explained
- **user-guides/**: Training, inference, monitoring, tuning
- **architecture/**: System design, data flow, design decisions
- **development/**: Extending framework (models, transforms, optimizers, metrics)
- **reference/**: Best practices, troubleshooting, FAQ

Documentation built with MkDocs Material theme, deployed to GitHub Pages.

## Code Style

- **Formatter**: ruff (line length: 100)
- **Linter**: ruff (pycodestyle, Pyflakes, isort, pep8-naming, pyupgrade, flake8-bugbear)
- **Docstrings**: Google-style with examples
- **Type hints**: Not enforced but encouraged for public APIs
- **Import order**: Standard lib → third-party → first-party (`ml_src`)

## Package Management

- Build system: setuptools
- Dependencies defined in `pyproject.toml`
- Console scripts: `ml-train`, `ml-inference`, `ml-split`, `ml-visualise`, `ml-init-config`
- Optional dev dependencies: `pip install -e ".[dev]"` (pytest, ruff, mkdocs)

## Git Workflow

- Main branch: `master`
- Runs directory (`runs/`) is gitignored
- User configs (`configs/*.yaml`) are gitignored (template at `ml_src/config_template.yaml`)
- Data directory (`data/`) is gitignored
