# PyTorch Image Classification & Segmentation Framework

[![Documentation Status](https://readthedocs.org/projects/nnclassification/badge/?version=latest)](https://nnclassification.readthedocs.io/en/latest/)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)

Production-ready framework for **image classification** and **semantic segmentation** with flexible architecture support, task-agnostic training pipeline, and index-based cross-validation. Supports multi-GPU training, differential privacy, federated learning, and comprehensive evaluation.

**Supported Tasks:**
- ğŸ¯ **Classification**: Multi-class image classification (ResNet, EfficientNet, custom CNNs)
- ğŸ¨ **Segmentation**: Semantic segmentation with pixel-level predictions (U-Net architectures)

## Key Features

**Task Support:**
- âœ… Image Classification (multi-class)
- âœ… Semantic Segmentation (pixel-level, multi-class)
- âœ… Task-agnostic training pipeline (automatically adapts to task type)

**Model Architectures:**
- **Classification**: All torchvision models (ResNet, EfficientNet, ConvNeXt, etc.), custom CNNs
- **Segmentation**: Simple U-Net (4-level encoder/decoder), extensible for custom architectures

**Loss Functions:**
- **Classification**: CrossEntropy, Focal Loss, Label Smoothing
- **Segmentation**: Dice Loss, Dice-BCE Loss, IoU Loss
- Registry-based system for easy extension

**Training Features:**
- Multi-GPU training (Hugging Face Accelerate)
- Mixed precision (PyTorch AMP) for 2-3x speedup
- Differential Privacy (Opacus) for privacy-sensitive data
- Federated Learning (Flower) for decentralized training
- Exponential Moving Average (EMA) for +0.5-2% accuracy
- Extensible callback system (early stopping, SWA, gradient clipping, etc.)
- Hyperparameter search (Optuna) with visualization

**Evaluation & Metrics:**
- **Classification**: Accuracy, Precision, Recall, F1, Confusion Matrix
- **Segmentation**: IoU (Intersection over Union), Dice coefficient, Pixel Accuracy
- Test-Time Augmentation (TTA) for +1-3% accuracy
- Ensemble inference from multiple models/folds
- Comprehensive TensorBoard integration

**Production Features:**
- ONNX export for deployment
- Model validation and benchmarking
- Index-based cross-validation (no data duplication)
- Automatic test set evaluation
- Comprehensive logging and visualization

## Quick Start

### Install
```bash
# Install in development mode (editable)
uv pip install -e .

# Or with development dependencies
uv pip install -e ".[dev]"
```

After installation, you can use the CLI commands from anywhere:
- `ml-init-config` - Generate dataset-specific configuration
- `ml-split` - Create dataset splits
- `ml-lr-finder` - Find optimal learning rate
- `ml-train` - Train models
- `ml-inference` - Run inference
- `ml-export` - Export models to ONNX format
- `ml-visualise` - Visualize data and predictions
- `ml-search` - Hyperparameter optimization (optional)

### Data Structure (MANDATORY)

**Classification Dataset:**
```
data/your_dataset/
â”œâ”€â”€ raw/              # Your original images organized by class
â”‚   â”œâ”€â”€ class1/
â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ class2/
â”‚       â”œâ”€â”€ img2.jpg
â”‚       â””â”€â”€ ...
â””â”€â”€ splits/           # Generated by ml-split (index files, no data duplication)
    â”œâ”€â”€ test.txt          # Single test set (SAME for all folds)
    â”œâ”€â”€ fold_0_train.txt
    â”œâ”€â”€ fold_0_val.txt
    â”œâ”€â”€ fold_1_train.txt
    â”œâ”€â”€ fold_1_val.txt
    â””â”€â”€ ...
```

**Segmentation Dataset:**
```
data/your_dataset/
â”œâ”€â”€ images/           # Original images
â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”œâ”€â”€ img2.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ masks/            # Segmentation masks (matching filenames)
â”‚   â”œâ”€â”€ img1.png      # Single-channel, pixel values = class indices
â”‚   â”œâ”€â”€ img2.png
â”‚   â””â”€â”€ ...
â””â”€â”€ splits/           # Generated by ml-split --task segmentation
    â”œâ”€â”€ test_images.txt
    â”œâ”€â”€ test_masks.txt
    â”œâ”€â”€ fold_0_train_images.txt
    â”œâ”€â”€ fold_0_train_masks.txt
    â””â”€â”€ ...
```

### Prepare Data & Train

#### Classification Workflow
```bash
# Step 1: Generate cross-validation splits
ml-split --raw_data data/my_dataset/raw --folds 5

# Step 2: Initialize configuration (auto-detects settings)
ml-init-config data/my_dataset
# Creates: configs/my_dataset_config.yaml

# Step 3: (Optional) Find optimal learning rate
ml-lr-finder --config configs/my_dataset_config.yaml

# Step 4: Train on fold 0
ml-train --config configs/my_dataset_config.yaml

# Custom hyperparameters via CLI
ml-train --config configs/my_dataset_config.yaml --batch_size 32 --lr 0.01

# Cross-validation (train other folds)
ml-train --config configs/my_dataset_config.yaml --fold 1
ml-train --config configs/my_dataset_config.yaml --fold 2
```

#### Segmentation Workflow
```bash
# Step 1: Generate segmentation splits
ml-split --raw_data data/my_dataset/images \
         --mask_data data/my_dataset/masks \
         --folds 5 \
         --task segmentation

# Step 2: Initialize segmentation config
ml-init-config data/my_dataset --task segmentation
# Auto-configured with:
#   - model: simple_unet
#   - loss: dice_loss
#   - metrics: IoU, Dice, pixel accuracy

# Step 3: Train segmentation model
ml-train --config configs/my_dataset_config.yaml

# Advanced: Custom model and loss
ml-train --config configs/my_dataset_config.yaml \
         --custom_architecture simple_unet \
         --loss dice_bce_loss \
         --batch_size 8
```

**Common Commands (Both Tasks):**
```bash
# Resume training
ml-train --config configs/my_dataset_config.yaml --resume runs/my_run/weights/last.pt

# Non-interactive config generation
ml-init-config data/my_dataset --yes
```

**Note:** After training completes, the model is automatically evaluated on the test set with task-appropriate metrics:
- **Classification**: Accuracy, Precision, Recall, F1, Confusion Matrix
- **Segmentation**: IoU (Intersection over Union), Dice coefficient, Pixel Accuracy

### Inference & Export
```bash
# Standard inference
ml-inference --checkpoint_path runs/my_dataset_base_fold_0/weights/best.pt

# Test-Time Augmentation (TTA) for +1-3% accuracy
ml-inference --checkpoint_path runs/my_dataset_base_fold_0/weights/best.pt --tta

# Ensemble multiple models for +2-5% accuracy
ml-inference --ensemble \
  runs/my_dataset_fold_0/weights/best.pt \
  runs/my_dataset_fold_1/weights/best.pt \
  runs/my_dataset_fold_2/weights/best.pt

# TTA + Ensemble for maximum accuracy (+3-8%)
ml-inference --ensemble \
  runs/my_dataset_fold_0/weights/best.pt \
  runs/my_dataset_fold_1/weights/best.pt \
  --tta

# Export model to ONNX format for deployment
ml-export --checkpoint runs/my_dataset_base_fold_0/weights/best.pt
# Creates: runs/my_dataset_base_fold_0/weights/best.onnx

# Export with validation
ml-export --checkpoint runs/my_dataset_base_fold_0/weights/best.pt --validate

# Export with comprehensive validation and benchmarking
ml-export --checkpoint runs/my_dataset_base_fold_0/weights/best.pt --comprehensive-validate --benchmark
```

### Visualization

```bash
# Launch TensorBoard
ml-visualise --mode launch --run_dir runs/base

# Visualize dataset samples
ml-visualise --mode samples --run_dir runs/base --split train --num_images 16

# Visualize model predictions (green=correct, red=incorrect)
ml-visualise --mode predictions --run_dir runs/base --split val

# Clean TensorBoard logs
ml-visualise --mode clean
```

Or use TensorBoard directly:
```bash
tensorboard --logdir runs/
```

### Dataset Statistics (Optional but Recommended)

```python
# Analyze dataset before training
from ml_src.core.data import analyze_dataset, generate_statistics_report, generate_all_plots

stats = analyze_dataset('data/my_dataset/raw')
generate_statistics_report(stats, 'data/my_dataset/splits/statistics.txt')
generate_all_plots(stats, 'data/my_dataset/splits/statistics/')

# Check for issues
if stats['imbalance_ratio'] > 3.0:
    print("âš ï¸ Dataset is imbalanced - consider focal loss or class weights")
```

### Model EMA (Exponential Moving Average)

Enable EMA for **0.5-2% accuracy improvement** with zero training cost:

```yaml
# In your config file
training:
  ema:
    enabled: true
    decay: 0.9999      # 0.999-0.9999 typical
    warmup_steps: 2000  # Optional
```

EMA maintains a shadow copy of model weights for better generalization. Both regular and EMA validation metrics are logged to TensorBoard (`Accuracy/val` and `Accuracy/val_ema`).

## Configuration

Generate dataset-specific configs with `ml-init-config`, then use CLI overrides:
```bash
# Create config (auto-detects dataset info)
ml-init-config data/my_dataset

# Edit if needed
vim configs/my_dataset_config.yaml

# Train with config (required)
ml-train --config configs/my_dataset_config.yaml
```

**CLI overrides** (override config file settings):
- `--config`: **Required** - Path to config file
- `--dataset_name`: Dataset name (used in run directory naming)
- `--data_dir`: Dataset path (must contain raw/ and splits/)
- `--fold`: Which CV fold to use (0-indexed, default: 0)
- `--batch_size`: Batch size
- `--num_epochs`: Training epochs
- `--lr`: Learning rate
- `--num_workers`: Data loading workers

**Full config documentation:** See `docs/configuration/README.md`

## Output Structure
```
runs/{dataset_name}_{params}_fold_{N}/  # Auto-named based on dataset and parameters
â”œâ”€â”€ config.yaml                          # Saved configuration
â”œâ”€â”€ summary.txt                          # Training summary
â”œâ”€â”€ weights/
â”‚   â”œâ”€â”€ best.pt                         # Best model (highest val metric)
â”‚   â””â”€â”€ last.pt                         # Latest checkpoint (for resuming)
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ train.log                       # Detailed training log
â”‚   â”œâ”€â”€ classification_report_*.txt     # Classification: precision, recall, F1
â”‚   â””â”€â”€ segmentation_metrics_*.txt      # Segmentation: IoU, Dice, pixel accuracy
â””â”€â”€ tensorboard/                         # TensorBoard logs
    â””â”€â”€ events.out.tfevents.*           # Task-specific metrics, plots, visualizations
```

**Task-specific outputs:**
- **Classification**: Confusion matrices, classification reports, per-class metrics
- **Segmentation**: IoU per class, Dice coefficients, predicted mask visualizations

**Example run directories:**
- `runs/hymenoptera_base_fold_0/` - Default training on fold 0
- `runs/hymenoptera_batch_32_fold_1/` - Batch size 32, fold 1
- `runs/custom_dataset_lr_0.01_epochs_50_fold_2/` - Custom params, fold 2

## Documentation

ğŸ“š **[Complete Documentation](docs/README.md)** - Comprehensive guides organized by topic

**Quick Links:**
- [Quick Start Guide](docs/getting-started/quick-start.md) - Train in 5 minutes
- [Data Preparation](docs/getting-started/data-preparation.md) - Organize your dataset
- [Configuration Reference](docs/configuration/README.md) - All settings explained
- [Training Guide](docs/user-guides/training.md) - Complete workflows
- [Monitoring & Visualization](docs/user-guides/monitoring.md) - TensorBoard and visualise.py
- [Troubleshooting](docs/reference/troubleshooting.md) - Common issues

**Documentation Sections:**
- **Getting Started** - Installation, data prep, quick start
- **Configuration** - Complete parameter reference
- **User Guides** - Training, inference, monitoring, tuning
- **Architecture** - System design and components
- **Development** - Extend and customize
- **Reference** - Best practices, troubleshooting, FAQ

## Requirements

- Python 3.8+
- PyTorch 2.0+
- TensorBoard 2.14+
- CUDA (optional, for GPU training)

See `pyproject.toml` for full dependencies.
