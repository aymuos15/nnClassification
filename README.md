# PyTorch Image Classifier

[![Documentation Status](https://readthedocs.org/projects/nnclassification/badge/?version=latest)](https://nnclassification.readthedocs.io/en/latest/)

Production-ready image classification framework with flexible architecture support and index-based cross-validation. Supports training, resumption, and comprehensive evaluation.

## Quick Start

### Install
```bash
# Install in development mode (editable)
pip install -e .

# Or with development dependencies
pip install -e ".[dev]"
```

After installation, you can use the CLI commands from anywhere:
- `ml-init-config` - Generate dataset-specific configuration
- `ml-train` - Train models
- `ml-inference` - Run inference
- `ml-split` - Create dataset splits
- `ml-visualise` - Visualize data and predictions

### Data Structure (MANDATORY)

```
data/your_dataset/
â”œâ”€â”€ raw/              # Your original images organized by class
â”‚   â”œâ”€â”€ class1/
â”‚   â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ class2/
â”‚       â”œâ”€â”€ img2.jpg
â”‚       â””â”€â”€ ...
â””â”€â”€ splits/           # Generated by splitting.py (index files, no data duplication)
    â”œâ”€â”€ test.txt          # Single test set (SAME for all folds)
    â”œâ”€â”€ fold_0_train.txt
    â”œâ”€â”€ fold_0_val.txt
    â”œâ”€â”€ fold_1_train.txt
    â”œâ”€â”€ fold_1_val.txt
    â””â”€â”€ ...
```

### Prepare Data & Train
```bash
# Step 1: Generate cross-validation splits (one time per dataset)
ml-split --raw_data data/my_dataset/raw --folds 5
# Output automatically saved to: data/my_dataset/splits/

# Step 2: Initialize configuration for your dataset (auto-detects settings)
ml-init-config data/my_dataset
# Creates: configs/my_dataset_config.yaml

# Non-interactive mode with defaults
ml-init-config data/my_dataset --yes

# Custom settings
ml-init-config data/my_dataset \
  --architecture efficientnet_b0 \
  --batch_size 32 \
  --num_epochs 50 \
  --lr 0.001

# Step 3: (Optional) Edit the generated config
vim configs/my_dataset_config.yaml

# Step 4: Train on fold 0 (automatically tests on held-out test set after training)
ml-train --config configs/my_dataset_config.yaml

# Custom hyperparameters via CLI (overrides config)
ml-train --config configs/my_dataset_config.yaml --batch_size 32 --lr 0.01

# Train other folds (cross-validation)
# Note: Test set is SAME for all folds, only train/val splits change
ml-train --config configs/my_dataset_config.yaml --fold 1
ml-train --config configs/my_dataset_config.yaml --fold 2

# Resume training
ml-train --config configs/my_dataset_config.yaml --resume runs/my_dataset_fold_0/weights/last.pt
```

**Note:** After training completes, the model is automatically evaluated on the test set. Test results are saved to `runs/{run_name}/logs/classification_report_test.txt` and logged to TensorBoard.

### Inference (Optional)
```bash
# Run inference manually on a specific checkpoint
ml-inference --checkpoint_path runs/my_dataset_base_fold_0/weights/best.pt
```

### Visualization

```bash
# Launch TensorBoard
ml-visualise --mode launch --run_dir runs/base

# Visualize dataset samples
ml-visualise --mode samples --run_dir runs/base --split train --num_images 16

# Visualize model predictions (green=correct, red=incorrect)
ml-visualise --mode predictions --run_dir runs/base --split val

# Clean TensorBoard logs
ml-visualise --mode clean
```

Or use TensorBoard directly:
```bash
tensorboard --logdir runs/
```

## Configuration

Generate dataset-specific configs with `ml-init-config`, then use CLI overrides:
```bash
# Create config (auto-detects dataset info)
ml-init-config data/my_dataset

# Edit if needed
vim configs/my_dataset_config.yaml

# Train with config (required)
ml-train --config configs/my_dataset_config.yaml
```

**CLI overrides** (override config file settings):
- `--config`: **Required** - Path to config file
- `--dataset_name`: Dataset name (used in run directory naming)
- `--data_dir`: Dataset path (must contain raw/ and splits/)
- `--fold`: Which CV fold to use (0-indexed, default: 0)
- `--batch_size`: Batch size
- `--num_epochs`: Training epochs
- `--lr`: Learning rate
- `--num_workers`: Data loading workers

**Full config documentation:** See `docs/configuration/README.md`

## Output Structure
```
runs/{dataset_name}_{params}_fold_{N}/  # Auto-named based on dataset and parameters
â”œâ”€â”€ config.yaml                          # Saved configuration
â”œâ”€â”€ summary.txt                          # Training summary
â”œâ”€â”€ weights/
â”‚   â”œâ”€â”€ best.pt                         # Best model (highest val accuracy)
â”‚   â””â”€â”€ last.pt                         # Latest checkpoint (for resuming)
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ train.log                       # Detailed training log
â”‚   â”œâ”€â”€ classification_report_train.txt
â”‚   â”œâ”€â”€ classification_report_val.txt
â”‚   â””â”€â”€ classification_report_test.txt  # Auto-generated test results
â””â”€â”€ tensorboard/                         # TensorBoard logs
    â””â”€â”€ events.out.tfevents.*           # Training/test metrics, plots, confusion matrices
```

**Example run directories:**
- `runs/hymenoptera_base_fold_0/` - Default training on fold 0
- `runs/hymenoptera_batch_32_fold_1/` - Batch size 32, fold 1
- `runs/custom_dataset_lr_0.01_epochs_50_fold_2/` - Custom params, fold 2

## Documentation

ðŸ“š **[Complete Documentation](docs/README.md)** - Comprehensive guides organized by topic

**Quick Links:**
- [Quick Start Guide](docs/getting-started/quick-start.md) - Train in 5 minutes
- [Data Preparation](docs/getting-started/data-preparation.md) - Organize your dataset
- [Configuration Reference](docs/configuration/README.md) - All settings explained
- [Training Guide](docs/user-guides/training.md) - Complete workflows
- [Monitoring & Visualization](docs/user-guides/monitoring.md) - TensorBoard and visualise.py
- [Troubleshooting](docs/reference/troubleshooting.md) - Common issues

**Documentation Sections:**
- **Getting Started** - Installation, data prep, quick start
- **Configuration** - Complete parameter reference
- **User Guides** - Training, inference, monitoring, tuning
- **Architecture** - System design and components
- **Development** - Extend and customize
- **Reference** - Best practices, troubleshooting, FAQ

## Requirements

- Python 3.8+
- PyTorch 2.0+
- TensorBoard 2.14+
- CUDA (optional, for GPU training)

See `pyproject.toml` for full dependencies.
