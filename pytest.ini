[pytest]
# =============================================================================
# Test Discovery
# =============================================================================
# Configure where pytest looks for tests and how it identifies them

# Search for tests in the 'tests' directory
testpaths = tests

# Test files must start with 'test_'
python_files = test_*.py

# Test classes must start with 'Test'
python_classes = Test*

# Test functions must start with 'test_'
python_functions = test_*

# =============================================================================
# Output and Behavior Options
# =============================================================================
# Configure pytest's output format and runtime behavior
# Run 'pytest --help' to see all available options
#
# -v: Verbose output (show individual test names)
# --strict-markers: Error on undefined markers (catches typos)
# --tb=short: Shorter traceback format
# --color=yes: Force colored output
# --strict-config: Error on config issues
# -ra: Show summary of all test outcomes except passed

addopts =
    -v
    --strict-markers
    --tb=short
    --color=yes
    --strict-config
    -ra

# =============================================================================
# Test Markers
# =============================================================================
# Markers allow categorizing and selectively running tests
# Usage: @pytest.mark.marker_name
# Filter: pytest -m "marker_name" or pytest -m "not marker_name"
#
# Examples:
#   pytest -m slow              # Run only slow tests
#   pytest -m "not slow"        # Skip slow tests  
#   pytest -m "unit and not slow"  # Run fast unit tests
#   pytest -m "workflow or integration"  # Run workflow OR integration tests

markers =
    # Speed-based markers
    slow: Marks tests as slow (typically >30s runtime). Run with: pytest -m slow. Skip with: pytest -m "not slow"
    
    # Test type markers  
    unit: Marks tests as unit tests (fast, isolated, no external dependencies). Run with: pytest -m unit
    
    integration: Marks tests as integration tests (test multiple components together). Run with: pytest -m integration
    
    workflow: Marks end-to-end workflow tests (full CLI command testing, validates docs/workflow.md workflows, ~45-70 min runtime). Run with: pytest tests/workflow/. Skip with: pytest -m "not workflow"
    
    # Dependency markers
    optuna: Marks tests that require optuna (install: pip install -e ".[optuna]"). Skip if not installed: pytest -m "not optuna"

# =============================================================================
# Warnings Configuration
# =============================================================================
# Control how pytest handles warnings from your code and dependencies

# Uncomment to treat warnings as errors (strict mode)
# filterwarnings =
#     error

# Uncomment to ignore specific warnings
# filterwarnings =
#     ignore::DeprecationWarning
#     ignore::PendingDeprecationWarning

# =============================================================================
# Coverage Configuration
# =============================================================================
# When running with pytest-cov (pytest --cov=ml_src)
# These options are used if pytest-cov is installed

# Uncomment to configure coverage reporting
# [coverage:run]
# source = ml_src
# omit = 
#     */tests/*
#     */conftest.py

# [coverage:report]
# precision = 2
# show_missing = True
# skip_covered = False

# =============================================================================
# Timeout Configuration  
# =============================================================================
# Default timeout for all tests (requires pytest-timeout)
# Individual tests can override with @pytest.mark.timeout(seconds)

# Uncomment to set global timeout
# timeout = 300
# timeout_method = thread

# =============================================================================
# Common pytest Commands
# =============================================================================
#
# Run all tests:
#   pytest
#
# Run specific test file:
#   pytest tests/test_architectures.py
#
# Run specific test:
#   pytest tests/test_architectures.py::test_model_loading
#
# Run tests matching pattern:
#   pytest -k "search"
#
# Run with coverage:
#   pytest --cov=ml_src --cov-report=html
#
# Run in parallel (requires pytest-xdist):
#   pytest -n auto
#
# Stop on first failure:
#   pytest -x
#
# Run last failed tests:
#   pytest --lf
#
# Show local variables in tracebacks:
#   pytest -l
#
# =============================================================================
